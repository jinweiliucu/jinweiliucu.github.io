---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---


<!-- <tr>
        <p>
          <h3>Research Overview</h3>
        </p>   
        <p align="justify">  
        The rapid growth in pervasive Internet of Things (IoT) and Deep Learning (DL) is creating a huge demand for applying DL to IoTs. However, IoTs impose capacity bottlenecks on State-of-the-Art (SOTA) DL technology, and thus, high-performance and low-latency DL services are challenging to provide. As a result, new methods are urgently needed to meet the demand from the DL-empowered IoTs. 
        </p>
  </td>
</tr> -->
   

<tr>
      <p align="justify"> 
        <h3> RECREATE: A Robust and Efficient Cooperative Resource Allocation and Scheduling System for High Resource Utilization and Throughput in Clouds (supported by NSF (Award Number: 2400459)) Investigators: Jinwei Liu (PI at Florida A&M University) </h3>
        
</h3>
      </p> 
      <p align="justify">  
        An efficient resource allocation and scheduling system helps to improve resource utilization and throughput while ensuring Service Level Objective (SLO) availability, which is crucial to cloud providers for high profit. The goal of this project is to develop a robust and efficient cooperative resource allocation and scheduling system to help cloud providers achieve high profit by improving resource utilization and throughput while ensuring SLO availability and robustness. The project breaks new ground by incorporating machine learning into cloud computing and designing and implementing a novel resource allocation and scheduling system for achieving high resource utilization and throughput while improving SLO availability and robustness in clouds, and it identifies the root cause of low resource utilization and enables new understanding of machine learning in optimizing resource allocation and scheduling in clouds. This research produces innovation in resource allocation and scheduling, and the results of this research help to advance theories, concepts, and methods in cloud computing. Specific aims of this project are to: 1) develop an efficient machine learning based resource allocation system consisting of cooperative demand-based resource allocation and cooperative opportunistic-based resource allocation for high resource utilization while ensuring SLO availability in clouds; 2) develop a robust machine learning based scheduling system for improving throughput and failure resilience 
      </p>
  
    <!-- <td style="border-left-style:none; border-left-width:medium; border-right-style:none; border-right-width:medium; border-top-style:solid; border-top-color: #CCCCCC;border-top-width:1px; border-bottom-style:none; border-bottom-width:medium" width="480">
      <img border="0" src="collaborativeAI.png" width="800" height="300">
    </td>
    <td style="border-left-style:none; border-left-width:medium; border-right-style:none; border-right-width:medium; border-top-style:solid; border-top-color: #CCCCCC;border-top-width:1px; border-bottom-style:none; border-bottom-width:1px" valign="top"> 
  </td> -->
</tr>

<tr>
      <p align="justify"> 
        <h3> Multi-Agent Energy Management Optimization (with Dr. Shen-Shyang Ho and Dr. Jie Li)</h3>
      </p> 
      <p align="justify">  
        Intelligent decision making is a key driving factor for future IoT systems. Today, network entities in IoT systems are able to not only sense the current state of the environment (e.g., sensing room temperature) but also take corresponding actions (e.g., turning the thermostat on or off) to maximize long-term rewards (e.g., keeping the room temperature at a target value or limiting the electricity demand below a certain level). Reinforcement learning algorithms have been used efficiently to enable network entities to obtain the optimal policy (e.g., decisions or actions) given their states when the state and action spaces are small. These algorithms, however, have faced significant challenges when dealing with high-dimensional environments. The recent development of deep learning has enabled deep reinforcement learning (DRL) methods to drive optimal policies for sophisticated and capable agents, which can outperform conventional rule-based operation policies such as in these challenging environments. Existing DRL studies mainly focus on simulated environments such as video games, and centralized training environments such as natural language processing. However, in IoT scenarios, multiple smart entities usually interact in a shared environment and make decisions at the same time. Therefore, we plan to address IoT system operation optimization with DRL with a focus on multi-device environments.
      </p>
  
    <td style="border-left-style:none; border-left-width:medium; border-right-style:none; border-right-width:medium; border-top-style:solid; border-top-color: #CCCCCC;border-top-width:1px; border-bottom-style:none; border-bottom-width:medium" width="480">
      <img border="0" src="./energy1.gif" width="800" height="300">
    </td>
    <td style="border-left-style:none; border-left-width:medium; border-right-style:none; border-right-width:medium; border-top-style:solid; border-top-color: #CCCCCC;border-top-width:1px; border-bottom-style:none; border-bottom-width:1px" valign="top"> 
  </td>
</tr>
  
  
  
    
<tr>
    <p align="justify"> 
      <h3>Bikesharing Rebalancing Optimization (with Dr. Shen-Shyang Ho)</h3>
    </p> 
    <p align="justify">  
      In shared mobility systems research, there is increasing interest in the use of reinforcement learning (RL) techniques for improving the resource supply balance and service level of systems. The goal of these techniques is to effectively produce a user incentivization policy scheme to encourage users of a shared mobility system (e.g. bikeshare systems) to slightly alter their travel behavior in exchange for a small monetary incentive. These slight changes in user behavior are intended to over time increase the service level of the shared mobility system and improve its profit margin. Reinforcement learning techniques are gaining popularity as an approach to solve this problem, as they can utilize deep learning for tasks that require many actions and produce a cumulative noisy reward signal. A reinforcement learning policy can be used to provide many incentives to users and then receive the service level of the target mobility system over time as a reward signal. We present an analysis and results of our extensive study on the effects of different frameworks for representing a shared mobility system on reinforcement learning performance for user incentivization, in terms of service level. We utilize bikeshare trip-data from Washington D.C.â€™s Capital Bikeshare system between 2015 and 2019 in our experiments to produce data-driven simulations for experimentation. In analysis, we show the relationship and effects on service level of user volume / mobility needs, resource supply availability, and incentivization budget. Further, we analyze the effectiveness of various reinforcement algorithms and various framework approaches.
    </p>  
  </td>


 <td style="border-left-style:none; border-left-width:medium; border-right-style:none; border-right-width:medium; border-top-style:solid; border-top-color: #CCCCCC;border-top-width:1px; border-bottom-style:none; border-bottom-width:medium" width="480">
    <img border="0" src="./bikeshare.gif" width="800" height="300">
  </td>
  
  <td style="border-left-style:none; border-left-width:medium; border-right-style:none; border-right-width:medium; border-top-style:solid; border-top-color: #CCCCCC;border-top-width:1px; border-bottom-style:none; border-bottom-width:1px" valign="top">

</tr>



